Documentación y Testing
-----------------------

    "Si no está en el manual está equivocado. Si está en el manual
    es redundante."

    -- Califa Omar, Alejandría, Año 634.

¿Pero cómo sabemos si el programa hace *exactamente* lo que dice el manual?

Bueno, pues *para eso* (entre otras cosas) están los tests [#]_. Los tests son
la rama militante de la documentación. La parte activa que se encarga de que ese manual no sea letra muerta e ignorada por perder contacto con la realidad,
sino un texto que refleja lo que realmente existe.

.. [#] También están para la gente mala que no documenta.

Si la realidad (el funcionamiento del programa) se aparta del ideal (el manual),
es el trabajo del test chiflar y avisar que está pasando. Para que esto sea
efectivo tenemos que cumplir varios requisitos:

* Los tests tienen que poder detectar todos los errores. (cobertura)

* Los tests tienen que ser ejecutados ante cada cambio, y las
  diferencias de resultado explicadas. (integración)

* El programador y el documentador y el tester (o sea uno) tiene que
  aceptar que hacer tests es necesario. Si se lo ve como una carga, no vale
  la pena: vas a aprender a ignorar las fallas, a hacer "pasar" los tests, a
  no hacer tests de las cosas que sabés que son difíciles. (ganas)

Por suerte en Python hay muchas herramientas que hacen que testear sea, si no divertido, por lo menos tolerable.

Docstrings
~~~~~~~~~~

Tomemos un ejemplo zonzo: una función para traducir al rosarino [#]_.

.. [#] Este ejemplo surgió de una discusión de PyAr. El código que contiene es
   tal vez un poco denso. No te asustes, lo importante no es el código, si no
   lo que hay alrededor.

.. admonition:: Lenguaje Rosarino

   Inventado (o popularizado) por Alberto Olmedo, el rosarino es un lenguaje en
   el cual la vocal acentuada X se reemplaza por XgasX con el acento al final
   (á por agasá, e por egasé, etc).

   Algunos ejemplos:

   rosarino => rosarigasino
   
   té => té (no se expanden monosílabos)
   
   brújula => brugasújula

   queso => quegaseso


Aquí tenemos una primera versión, que funciona sólo en palabras con acento ortográfico:

.. class:: titulo-listado

gaso1.py

.. class:: listado

.. code-block:: python
   :linenos:
   :include: codigo/4/gaso1.py

Esas cadenas debajo de cada ``def`` se llaman docstrings y *siempre* hay que
usarlas. ¿Por qué?

* Es el lugar "oficial" para explicar qué hace cada función

* ¡Sirven como ayuda interactiva!

  .. code-block:: pycon

    >>> import gaso1
    >>> help(gaso1.gas)

  Help on function gas in module gaso1:

  gas(letra)
      Dada una letra X devuelve XgasX excepto si X es una vocal acentuada,
      en cuyo caso devuelve la primera X sin acento.

      El uso de normalize lo saqué de google.

* Usando una herramienta como `epydoc <http://epydoc.sourceforge.net/>`_ se
  pueden usar para generar una guía de referencia de tu módulo (¡manual gratis!)

* Son el hogar de los doctests.

Doctests
~~~~~~~~

    "Los comentarios mienten. El código no."

    -- Ron Jeffries


Un comentario mentiroso es peor que ningún comentario. Y los comentarios se
vuelven mentira porque el código cambia y nadie edita los comentarios. Es
el problema de repetirse: uno ya dijo lo que quería en el código, y tiene que
volver a explicarlo en un comentario; a la larga las copias divergen,
y siempre el que está equivocado es el comentario.

Un doctest permite **asegurar** que el comentario es cierto, porque el
comentario tiene código de su lado, no es sólo palabras.

Y acá viene la primera cosa importante de testing: Uno quiere testear **todos**
los comportamientos intencionales del código.

Si el código se supone que ya hace algo bien, aunque sea algo muy chiquitito, es
el momento ideal para empezar a hacer testing. Si vas a esperar a que la función
sea "interesante", ya va a ser muy tarde. Vas a tener un déficit de tests, vas
a tener que ponerte un día sólo a escribir tests, y vas a decir que testear es aburrido.

¿Cómo sé yo que esa regexp en ``gaso1.py`` hace lo que yo quiero? ¡Porque la
probé! Como no soy el mago de las expresiones regulares que las saca de la
galera y le andan a la primera, hice esto en el intérprete interactivo
(reemplacé la funcion ``gas`` con una versión boba):

.. code-block:: pycon

    >>> import re
    >>> palabra=u'cámara'
    >>> print re.sub(u'([\xe1\xe9\xed\xf3\xfa])',
    ...     lambda x: x.group(0)+'gas'+x.group(0),palabra,1)
    
    cágasámara

¿Y como sé que la función ``gas`` hace lo que quiero? Porque hice esto:

.. code-block:: pycon

    >>> import unicodedata
    >>> def gas(letra):
    ...     return u'%sgas%s'%(unicodedata.normalize('NFKD',
    ...         letra).encode('ASCII', 'ignore'), letra)
    >>> print gas(u'á')
    agasá
    >>> print gas(u'a')
    agasa


Si no hubiera hecho ese test manual no tendría la más mínima confianza en este
código, y creo que casi todos hacemos esta clase de cosas, ¿o no?.

El problema con este testing manual ad hoc es que lo hacemos una vez, la función
hace lo que se supone debe hacer (al menos por el momento), y nos olvidamos.

Por suerte *no tiene Por qué ser así*, gracias a los doctests.

De hecho, el doctest es poco más que cortar y pegar esos tests informales que
mostré arriba. Veamos la versión con doctests:

.. class:: titulo-listado

gaso2.py

.. class:: listado

.. code-block:: python
   :linenos:
   :include: codigo/4/gaso2.py

Eso es todo lo que se necesita para implementar doctests. ¡En serio!. ¿Y cómo
hago para saber si los tests pasan o fallan? Hay muchas maneras. Tal vez la
que más me gusta es usar `Nose <http://somethingaboutorange.com/mrl/projects/nose/>`_, 
una herramienta cuyo único objetivo es hacer que testear sea más fácil.

::

    [ralsina@hp python-no-muerde]$ nosetests --with-doctest -v gaso2.py
    Doctest: gaso2.gas ... ok
    Doctest: gaso2.gasear ... ok

    ----------------------------------------------------------------------
    Ran 2 tests in 0.035s

    OK
    

Lo que hizo nose es "descubrimiento de tests" (test discovery). Toma la carpeta
actual o el archivo que indiquemos (en este caso ``gaso2.py``), encuentra las
cosas que parecen tests y las usa. El parámetro ``--with-doctest`` es para que reconozca doctests (por default los ignora), y el ``-v`` es para que muestre
cada cosa que prueba.

De ahora en más, cada vez que el programa se modifique, volvemos a correr el test suite (eso significa "un conjunto de tests"). Si falla alguno que antes andaba,
es una regresión, paramos de romper y la arreglamos. Si pasa alguno que antes
fallaba, es un avance, nos felicitamos y nos damos un caramelo.

Dentro del limitado alcance de nuestro programa actual, lo que hace, lo hace
bien. Obviamente hay muchas cosas que hace mal:

.. code-block:: pycon

    >>> import gaso2
    >>> gaso2.gasear('rosarino')
    'rosarino'
    >>> print 'OH NO!'
    OH NO!

¿Qué hacemos entonces? ¡Agregamos un test que falla! Bienvenido al mundo del TDD
o "Desarrollo impulsado por tests" (Test Driven Development). La idea es que,
en general, si sabemos que hay un bug, seguimos este proceso:

* Creamos un test que falla.
* Arreglamos el código para que no falle el test.
* Verificamos que no rompimos otra cosa usando el test suite.

Un test que falla es **bueno** porque nos marca qué hay que corregir. Si los
tests son piolas, y cada uno prueba una sola cosa [#]_ , entonces hasta nos va a
indicar qué parte del código es la que está rota.

.. [#] Un test que prueba muchas cosas juntas no es un buen test, porque al
       fallar no sabés Por qué. Eso se llama granularidad de los tests y es muy
       importante.

Entonces, el problema de ``gaso2.py`` es que no funciona cuando no hay acentos
ortográficos. ¿Solución? Una función que diga donde está el acento prosódico en
una palabra [#]_.

.. [#] Y en este momento agradezcan que esto es castellano, que es un idioma
       casi obsesivo compulsivo en su regularidad.

Modificamos ``gasear`` así:

.. class:: titulo-listado

gaso3.py

.. class:: listado

.. code-block:: python
   :linenos:
   :linenos_offset:
   :include: codigo/4/gaso3.py
   :start-at: def gasear(palabra):

¿Notaste que agregar tests de esta forma no se siente como una carga?

Es parte natural de escribir el código, pienso, "uy, esto no debe andar", meto
el test como creo que debería ser en el docstring, y de ahora en más sé si eso
anda o no.

Por otro lado te da la tranquilidad de "no estoy rompiendo nada". Por lo menos
nada que no estuviera funcionando exclusivamente por casualidad.

Por ejemplo, ``gaso1.py`` pasaría el test de la palabra "la" y ``gaso2.py``
fallaría, pero no porque ``gaso1.py`` estuviera haciendo algo bien, sino
porque respondía de forma afortunada.

Cobertura
~~~~~~~~~

Es importante que nuestros tests "cubran" el código. Es decir que cada parte sea
usada por lo menos una vez. Si hay un fragmento de código que ningún test
utiliza nos faltan tests (o nos sobra código [#]_)

.. [#] El código muerto en una aplicación es un problema serio, molesta cuando
       se intenta depurar porque está metido en el medio de las partes que sí
       se usan y distrae.

La forma de saber qué partes de nuestro código están cubiertas es con una
herramienta de cobertura ("coverage tool"). Veamos una en acción::

    [ralsina@hp python-no-muerde]$ nosetests --with-coverage --with-doctest \
        -v gaso3.py buscaacento1.py
        
    Doctest: gaso3.gas ... ok
    Doctest: gaso3.gasear ... ok
    Doctest: buscaacento1.busca_acento ... ok

    Name              Stmts   Exec  Cover   Missing
    -----------------------------------------------
    buscaacento1          6      6   100%
    encodings.ascii      19      0     0%   9-42
    gaso3                10     10   100%
    -----------------------------------------------
    TOTAL                35     16    45%
    ----------------------------------------------------------------------
    Ran 3 tests in 0.018s

    OK

Al usar la opción ``--with-coverage``, nose usa el módulo ``coverage.py`` para
ver cuáles líneas de código se usan y cuales no. Lamentablemente el reporte
incluye un módulo de sistema, ``encodings.ascii`` lo que hace que los
porcentajes no sean correctos.

Una manera de tener un reporte más preciso es correr ``coverage report`` luego
de correr nosetests::

    [ralsina@hp python-no-muerde]$ coverage report
    Name           Stmts   Exec  Cover
    ----------------------------------
    buscaacento1       6      6   100%
    gaso3             10     10   100%
    ----------------------------------
    TOTAL             16     16   100%


Ignorando ``encodings.ascii`` (que no es nuestro), tenemos 100% de cobertura.
Ese es el ideal. Cuando ese porcentaje baje, deberíamos tratar de ver qué parte
del código nos estamos olvidando de testear, pero es casi imposible tener 100%
de cobertura en casi cualquier programa no trivial.

Coverage también puede crear reportes HTML mostrando cuales líneas se usan y
cuales no, para ayudar a diseñar tests que las ejerciten.

Mocking
~~~~~~~

    La única manera de reconocer al maestró del disfraz es su risa. Se ríe
    "jo jo jo".

    -- Inspector Austin, Backyardigans

A veces para probar algo, se necesita un objeto, y no es práctico usar el objeto
real por diversos motivos, entre otros:

* Puede ser un objeto "caro": una base de datos.

* Puede ser un objeto "inestable": un sensor de temperatura.

* Puede ser un objeto "malo": por ejemplo un componente que aún no está
  implementado.

* Puede ser un objeto "no disponible": una página web, un recurso de red.

* Simplemente quiero "separar" los tests, quiero que los errores de un
  componente no se propaguen a otro. [#]_

* Estamos haciendo doctests de un método de una clase: la clase no está
  instanciada al ejecutar el doctest.


.. [#] Esta separación de los elementos funcionales es lo que hace que esto sea
        "unit testing": probamos cada unidad funcional del código.

Para resolver este problema se usa mocking. ¿Qué es eso? Es una manera de crear
objetos falsos que hacen lo que uno quiere y podemos usar en lugar del real.

Una herramienta sencilla de mocking para usar en doctests es
`minimock <http://pypi.python.org/pypi/MiniMock>`_.

Apartándonos de nuestro ejemplo por un momento, ya que no se presta a usar
mocking sin inventar nada ridículo, pero aún así sabiendo que estamos
persiguiendo hormigas con aplanadoras...

.. class:: titulo-listado

mock1.py

.. class:: listado

.. code-block:: python
   :linenos:
   :linenos_offset:
   :include: codigo/4/mock1.py
   :start-at: def largo_de_pagina


